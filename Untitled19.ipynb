{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9c92c79-6738-4439-9de6-4ac46924a4cf",
   "metadata": {},
   "source": [
    "## Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bda186d-99ab-4a09-9b9c-8715ef9fce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the video URLs of the first five videos from a web page, you would typically use web scraping techniques. Assuming you're scraping from a website like YouTube, you would need to inspect the HTML structure of the page to identify the elements containing the video URLs.\n",
    "\n",
    "Below is an example Python program using the Beautiful Soup library to scrape video URLs from a YouTube search result page. This program extracts the video URLs of the first five videos displayed on the search results page:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_urls(search_query):\n",
    "    # Construct the search URL\n",
    "    search_url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
    "\n",
    "    # Send a GET request to the search URL\n",
    "    response = requests.get(search_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all elements containing video links\n",
    "        video_links = soup.find_all('a', {'class': 'yt-simple-endpoint'})\n",
    "\n",
    "        # Extract video URLs from the first five video links\n",
    "        video_urls = []\n",
    "        for link in video_links:\n",
    "            if len(video_urls) >= 5:\n",
    "                break\n",
    "            href = link.get('href')\n",
    "            if href.startswith('/watch?v='):\n",
    "                video_url = f\"https://www.youtube.com{href}\"\n",
    "                video_urls.append(video_url)\n",
    "\n",
    "        return video_urls\n",
    "    else:\n",
    "        print(\"Failed to fetch search results.\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "search_query = \"python programming tutorial\"\n",
    "video_urls = extract_video_urls(search_query)\n",
    "print(\"Video URLs:\")\n",
    "for url in video_urls:\n",
    "    print(url)\n",
    "This program sends a GET request to the YouTube search URL for a given search query using the requests library. It then parses the HTML content of the page using Beautiful Soup and extracts the video URLs from the first five video links found on the page. Finally, it prints the extracted video URLs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85128aea-0ecb-4ddf-80e6-893a3e5cc89d",
   "metadata": {},
   "source": [
    "## Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c806d8-7e87-43b0-b97e-0e74b03566aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "To extract the URLs of the video thumbnails of the first five videos from a webpage (such as YouTube), you can use similar web scraping techniques as before. This time, you'll be looking for the elements containing the thumbnail URLs instead of the video URLs.\n",
    "\n",
    "Here's a Python program using Beautiful Soup to scrape the thumbnail URLs of the first five videos from a YouTube search result page:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_thumbnail_urls(search_query):\n",
    "    # Construct the search URL\n",
    "    search_url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
    "\n",
    "    # Send a GET request to the search URL\n",
    "    response = requests.get(search_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all elements containing video thumbnails\n",
    "        thumbnails = soup.find_all('img', {'class': 'style-scope yt-img-shadow'})\n",
    "\n",
    "        # Extract thumbnail URLs from the first five thumbnails\n",
    "        thumbnail_urls = []\n",
    "        for thumbnail in thumbnails:\n",
    "            if len(thumbnail_urls) >= 5:\n",
    "                break\n",
    "            thumbnail_url = thumbnail.get('src')\n",
    "            thumbnail_urls.append(thumbnail_url)\n",
    "\n",
    "        return thumbnail_urls\n",
    "    else:\n",
    "        print(\"Failed to fetch search results.\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "search_query = \"python programming tutorial\"\n",
    "thumbnail_urls = extract_thumbnail_urls(search_query)\n",
    "print(\"Thumbnail URLs:\")\n",
    "for url in thumbnail_urls:\n",
    "    print(url)\n",
    "This program follows a similar structure to the previous one but looks for img elements with a specific class that contains the thumbnail URLs. It extracts the URLs of the thumbnail images from the first five thumbnails found on the page.\n",
    "\n",
    "Remember to install the required libraries (requests and beautifulsoup4) if you haven't already done so:\n",
    "\n",
    "\n",
    "pip install requests beautifulsoup4\n",
    "As always, be sure to respect the website's terms of service and guidelines when scraping its content. Additionally, keep in mind that the HTML structure of the page may change over time, so you may need to adjust the code accordingly to ensure it continues to work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40364b40-e47c-4136-bb34-fc2db79f7b91",
   "metadata": {},
   "source": [
    "## Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697be9b8-b671-4559-b18a-864dde51e216",
   "metadata": {},
   "outputs": [],
   "source": [
    "Import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_titles(search_query):\n",
    "    # Construct the search URL\n",
    "    search_url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
    "\n",
    "    # Send a GET request to the search URL\n",
    "    response = requests.get(search_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all elements containing video titles\n",
    "        title_elements = soup.find_all('a', {'id': 'video-title'})\n",
    "\n",
    "        # Extract titles from the first five title elements\n",
    "        video_titles = []\n",
    "        for title_element in title_elements:\n",
    "            if len(video_titles) >= 5:\n",
    "                break\n",
    "            video_title = title_element.get('title')\n",
    "            video_titles.append(video_title)\n",
    "\n",
    "        return video_titles\n",
    "    else:\n",
    "        print(\"Failed to fetch search results.\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "search_query = \"python programming tutorial\"\n",
    "video_titles = extract_video_titles(search_query)\n",
    "print(\"Video Titles:\")\n",
    "for title in video_titles:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8b7bf3-1872-4200-9f03-126df5c4e267",
   "metadata": {},
   "source": [
    "## Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfa259-e3a7-42de-baa1-e94ada59df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_video_views(search_query):\n",
    "    # Construct the search URL\n",
    "    search_url = f\"https://www.youtube.com/results?search_query={search_query}\"\n",
    "\n",
    "    # Send a GET request to the search URL\n",
    "    response = requests.get(search_url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the HTML content of the page\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Find all elements containing video views\n",
    "        view_elements = soup.find_all('span', {'class': 'style-scope ytd-video-meta-block'})\n",
    "\n",
    "        # Extract views from the first five view elements\n",
    "        video_views = []\n",
    "        for view_element in view_elements:\n",
    "            if len(video_views) >= 5:\n",
    "                break\n",
    "            view_text = view_element.get_text(strip=True)\n",
    "            if view_text.endswith('views'):\n",
    "                video_views.append(view_text)\n",
    "\n",
    "        return video_views\n",
    "    else:\n",
    "        print(\"Failed to fetch search results.\")\n",
    "        return []\n",
    "\n",
    "# Example usage:\n",
    "search_query = \"python programming tutorial\"\n",
    "video_views = extract_video_views(search_query)\n",
    "print(\"Number of Views:\")\n",
    "for views in video_views:\n",
    "    print(views)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e82b4-6aa1-441c-b104-ea0cebb3a7f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
